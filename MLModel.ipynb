{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.initializers import glorot_uniform\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import Xception\n",
    "from tensorflow.keras.layers import (\n",
    "    Flatten,\n",
    "    Dense,\n",
    "    AveragePooling2D,\n",
    "    Dropout\n",
    ")\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.callbacks import (\n",
    "    EarlyStopping,\n",
    "    ModelCheckpoint,\n",
    "    LearningRateScheduler\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHAPE = 224\n",
    "BATCH_SIZE = 8\n",
    "model = Xception(\n",
    "    input_shape=(SHAPE, SHAPE, 3),\n",
    "    include_top=False,\n",
    "    weights='imagenet'\n",
    ")\n",
    "\n",
    "x = model.output\n",
    "x = AveragePooling2D(pool_size=(2, 2))(x)\n",
    "x = Dense(32, activation='relu')(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(4, activation='softmax',\n",
    "          kernel_regularizer=l2(.0005))(x)\n",
    "model = Model(inputs=model.inputs, outputs=x)\n",
    "opt = SGD(lr=0.0001, momentum=.9)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1056 images belonging to 4 classes.\n",
      "Found 219 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "valid_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=0,\n",
    "    width_shift_range=0.0,\n",
    "    height_shift_range=0.0,\n",
    "    horizontal_flip=False\n",
    ")\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'train/',\n",
    "    target_size=(SHAPE, SHAPE),\n",
    "    shuffle=True,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    ")\n",
    "valid_generator = valid_datagen.flow_from_directory(\n",
    "    'valid/',\n",
    "    target_size=(SHAPE, SHAPE),\n",
    "    shuffle=True,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystop = EarlyStopping(monitor='val_loss',\n",
    "                          patience=4,\n",
    "                          verbose=1)\n",
    "checkpoint = ModelCheckpoint(\n",
    "    \"model-weights/xception_checkpoint.h5\",\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-6-cf7b27d17515>:5: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/20\n",
      "132/132 [==============================] - ETA: 0s - loss: 1.4128 - accuracy: 0.2472\n",
      "Epoch 00001: val_loss improved from inf to 1.40804, saving model to model-weights\\xception_checkpoint.h5\n",
      "132/132 [==============================] - 596s 5s/step - loss: 1.4128 - accuracy: 0.2472 - val_loss: 1.4080 - val_accuracy: 0.2694\n",
      "Epoch 2/20\n",
      "132/132 [==============================] - ETA: 0s - loss: 1.3345 - accuracy: 0.3333\n",
      "Epoch 00002: val_loss improved from 1.40804 to 1.33115, saving model to model-weights\\xception_checkpoint.h5\n",
      "132/132 [==============================] - 613s 5s/step - loss: 1.3345 - accuracy: 0.3333 - val_loss: 1.3311 - val_accuracy: 0.3607\n",
      "Epoch 3/20\n",
      "132/132 [==============================] - ETA: 0s - loss: 1.2798 - accuracy: 0.4195\n",
      "Epoch 00003: val_loss improved from 1.33115 to 1.26672, saving model to model-weights\\xception_checkpoint.h5\n",
      "132/132 [==============================] - 637s 5s/step - loss: 1.2798 - accuracy: 0.4195 - val_loss: 1.2667 - val_accuracy: 0.4155\n",
      "Epoch 4/20\n",
      "132/132 [==============================] - ETA: 0s - loss: 1.2053 - accuracy: 0.4877\n",
      "Epoch 00004: val_loss improved from 1.26672 to 1.21452, saving model to model-weights\\xception_checkpoint.h5\n",
      "132/132 [==============================] - 676s 5s/step - loss: 1.2053 - accuracy: 0.4877 - val_loss: 1.2145 - val_accuracy: 0.4749\n",
      "Epoch 5/20\n",
      "132/132 [==============================] - ETA: 0s - loss: 1.1630 - accuracy: 0.5038\n",
      "Epoch 00005: val_loss improved from 1.21452 to 1.14371, saving model to model-weights\\xception_checkpoint.h5\n",
      "132/132 [==============================] - 715s 5s/step - loss: 1.1630 - accuracy: 0.5038 - val_loss: 1.1437 - val_accuracy: 0.5297\n",
      "Epoch 6/20\n",
      "132/132 [==============================] - ETA: 0s - loss: 1.0886 - accuracy: 0.5322\n",
      "Epoch 00006: val_loss improved from 1.14371 to 1.07397, saving model to model-weights\\xception_checkpoint.h5\n",
      "132/132 [==============================] - 716s 5s/step - loss: 1.0886 - accuracy: 0.5322 - val_loss: 1.0740 - val_accuracy: 0.5571\n",
      "Epoch 7/20\n",
      "132/132 [==============================] - ETA: 0s - loss: 0.9959 - accuracy: 0.6013\n",
      "Epoch 00007: val_loss improved from 1.07397 to 1.01756, saving model to model-weights\\xception_checkpoint.h5\n",
      "132/132 [==============================] - 754s 6s/step - loss: 0.9959 - accuracy: 0.6013 - val_loss: 1.0176 - val_accuracy: 0.6073\n",
      "Epoch 8/20\n",
      "132/132 [==============================] - ETA: 0s - loss: 0.9524 - accuracy: 0.6108\n",
      "Epoch 00008: val_loss improved from 1.01756 to 0.95298, saving model to model-weights\\xception_checkpoint.h5\n",
      "132/132 [==============================] - 698s 5s/step - loss: 0.9524 - accuracy: 0.6108 - val_loss: 0.9530 - val_accuracy: 0.5982\n",
      "Epoch 9/20\n",
      "132/132 [==============================] - ETA: 0s - loss: 0.8985 - accuracy: 0.6259\n",
      "Epoch 00009: val_loss improved from 0.95298 to 0.90591, saving model to model-weights\\xception_checkpoint.h5\n",
      "132/132 [==============================] - 646s 5s/step - loss: 0.8985 - accuracy: 0.6259 - val_loss: 0.9059 - val_accuracy: 0.6484\n",
      "Epoch 10/20\n",
      "132/132 [==============================] - ETA: 0s - loss: 0.8475 - accuracy: 0.6686\n",
      "Epoch 00010: val_loss improved from 0.90591 to 0.85139, saving model to model-weights\\xception_checkpoint.h5\n",
      "132/132 [==============================] - 696s 5s/step - loss: 0.8475 - accuracy: 0.6686 - val_loss: 0.8514 - val_accuracy: 0.6621\n",
      "Epoch 11/20\n",
      "132/132 [==============================] - ETA: 0s - loss: 0.8229 - accuracy: 0.6648\n",
      "Epoch 00011: val_loss improved from 0.85139 to 0.81066, saving model to model-weights\\xception_checkpoint.h5\n",
      "132/132 [==============================] - 709s 5s/step - loss: 0.8229 - accuracy: 0.6648 - val_loss: 0.8107 - val_accuracy: 0.6621\n",
      "Epoch 12/20\n",
      "132/132 [==============================] - ETA: 0s - loss: 0.7618 - accuracy: 0.7112\n",
      "Epoch 00012: val_loss improved from 0.81066 to 0.77202, saving model to model-weights\\xception_checkpoint.h5\n",
      "132/132 [==============================] - 732s 6s/step - loss: 0.7618 - accuracy: 0.7112 - val_loss: 0.7720 - val_accuracy: 0.6758\n",
      "Epoch 13/20\n",
      "132/132 [==============================] - ETA: 0s - loss: 0.6850 - accuracy: 0.7453\n",
      "Epoch 00013: val_loss improved from 0.77202 to 0.73730, saving model to model-weights\\xception_checkpoint.h5\n",
      "132/132 [==============================] - 641s 5s/step - loss: 0.6850 - accuracy: 0.7453 - val_loss: 0.7373 - val_accuracy: 0.7078\n",
      "Epoch 14/20\n",
      "132/132 [==============================] - ETA: 0s - loss: 0.6911 - accuracy: 0.7339\n",
      "Epoch 00014: val_loss improved from 0.73730 to 0.71180, saving model to model-weights\\xception_checkpoint.h5\n",
      "132/132 [==============================] - 645s 5s/step - loss: 0.6911 - accuracy: 0.7339 - val_loss: 0.7118 - val_accuracy: 0.7215\n",
      "Epoch 15/20\n",
      "132/132 [==============================] - ETA: 0s - loss: 0.6314 - accuracy: 0.7633\n",
      "Epoch 00015: val_loss improved from 0.71180 to 0.67593, saving model to model-weights\\xception_checkpoint.h5\n",
      "132/132 [==============================] - 667s 5s/step - loss: 0.6314 - accuracy: 0.7633 - val_loss: 0.6759 - val_accuracy: 0.7352\n",
      "Epoch 16/20\n",
      "132/132 [==============================] - ETA: 0s - loss: 0.5939 - accuracy: 0.7708\n",
      "Epoch 00016: val_loss improved from 0.67593 to 0.66232, saving model to model-weights\\xception_checkpoint.h5\n",
      "132/132 [==============================] - 702s 5s/step - loss: 0.5939 - accuracy: 0.7708 - val_loss: 0.6623 - val_accuracy: 0.7352\n",
      "Epoch 17/20\n",
      "132/132 [==============================] - ETA: 0s - loss: 0.6003 - accuracy: 0.7661\n",
      "Epoch 00017: val_loss improved from 0.66232 to 0.65099, saving model to model-weights\\xception_checkpoint.h5\n",
      "132/132 [==============================] - 661s 5s/step - loss: 0.6003 - accuracy: 0.7661 - val_loss: 0.6510 - val_accuracy: 0.7580\n",
      "Epoch 18/20\n",
      "132/132 [==============================] - ETA: 0s - loss: 0.5571 - accuracy: 0.7898\n",
      "Epoch 00018: val_loss improved from 0.65099 to 0.60858, saving model to model-weights\\xception_checkpoint.h5\n",
      "132/132 [==============================] - 679s 5s/step - loss: 0.5571 - accuracy: 0.7898 - val_loss: 0.6086 - val_accuracy: 0.7626\n",
      "Epoch 19/20\n",
      "132/132 [==============================] - ETA: 0s - loss: 0.5337 - accuracy: 0.7964\n",
      "Epoch 00019: val_loss improved from 0.60858 to 0.60256, saving model to model-weights\\xception_checkpoint.h5\n",
      "132/132 [==============================] - 622s 5s/step - loss: 0.5337 - accuracy: 0.7964 - val_loss: 0.6026 - val_accuracy: 0.7671\n",
      "Epoch 20/20\n",
      "132/132 [==============================] - ETA: 0s - loss: 0.4979 - accuracy: 0.8220\n",
      "Epoch 00020: val_loss improved from 0.60256 to 0.58200, saving model to model-weights\\xception_checkpoint.h5\n",
      "132/132 [==============================] - 620s 5s/step - loss: 0.4979 - accuracy: 0.8220 - val_loss: 0.5820 - val_accuracy: 0.7763\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    epochs=20,\n",
    "    callbacks=[earlystop, checkpoint],\n",
    "    validation_data=valid_generator\n",
    ")\n",
    "# Save our model for inference\n",
    "model.save(\"model-weights/xception.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from PIL import Image\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = 'model-weights/xception.h5'\n",
    "model = load_model(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_img(input_image, shape):\n",
    "    img = Image.open(input_image).convert('RGB')\n",
    "    img = img.resize((shape, shape))\n",
    "    img = image.img_to_array(img)\n",
    "    return np.reshape(img, [1, shape, shape, 3])/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_img = load_img(\"./train/cartier/cartier-0-5331.jpg\", 224)\n",
    "pred_img = load_img(\"omega.jpg\", 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_DICT = {\n",
    "    0: 'Cartier',\n",
    "    1: 'Omega',\n",
    "    2: 'Rolex',\n",
    "    3: 'Seiko'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0048708576"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[pred for pred in model.predict(pred_img)[0]][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = CLASS_DICT[np.argmax(model.predict(pred_img))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Omega'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Cartier', 0.1), ('Omega', 0.1), ('Rolex', 0.4), ('Seiko', 0.4)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(list(CLASS_DICT.values()), [0.1, 0.1, 0.4, 0.4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Omega'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Cartier', 'O'), ('Omega', 'm'), ('Rolex', 'e'), ('Seiko', 'g')]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(\n",
    "\t\t\tlist(CLASS_DICT.values()),\n",
    "\t\t\t[prediction for prediction in pred]\n",
    "\t\t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O', 'm', 'e', 'g', 'a']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[prediction for prediction in pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(pred_img)\n",
    "type([round(prediction, 4) for prediction in map(float, pred[0])][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
